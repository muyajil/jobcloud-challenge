{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Idea\n",
    "\n",
    "- There are several ways to utilize this dataset to help people write job titles\n",
    "- I propose some kind of autocomplete feature.\n",
    "- That means the user will type part of a word and receive a list of possible words to autocomplete the current word.\n",
    "- This is a simpler but more realistic approach than recommending complete job titles, since as evident by the data, the job titles are written rather subjective, sometimes with a motivational intro. \n",
    "- Recommending single words is a less complex problem, and also might be a precursor to more sophisticated recommendation system.\n",
    "- Also using a character based model that predicts the next character might be an interesting model, however models like this can predict gibberish, depending on the number of datapoints. This is of course not desired for a user facing feature. Therefore we fall back to recommending single words from a known corpus.\n",
    "- In cases like these it often makes sense simplify the problem as much as possible, so that we can establish a baseline for such a feature and later continue improving it.\n",
    "- Essentially this is a classification problem where the possible words are the target classes.\n",
    "- The input to the model is the input of the user.\n",
    "\n",
    "## Preprocess Data\n",
    "\n",
    "- To be able to build such a system we want to extract the single words from the job titles\n",
    "- After that we will do the following preprocessing steps:\n",
    "    - Lowercase all words to reduce the number of target classes\n",
    "    - Remove special characters\n",
    "    - Remove \"m/w\" gender specification\n",
    "    - Remove workloads from the title\n",
    "    - Remove words with less than 3 characters (because that is the history we will try to use to predict the next word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5051"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles = pd.read_csv('jobcloud_published_job_titles.csv', header=None)[0]\n",
    "# Lowercase job titles\n",
    "job_titles = job_titles.str.lower()\n",
    "# Remove special characters and numbers (except for umlauts and french accents)\n",
    "job_titles = job_titles.str.replace(\"[^A-Za-z \\u00e4\\u00f6\\u00fc\\u00e1\\u00e8\\u00e9]\", ' ')\n",
    "# Split titles into words\n",
    "job_titles = job_titles.str.split(' ')\n",
    "# Remove lone spaces/empty strings\n",
    "job_titles = job_titles.map(lambda x: list(filter(lambda y: y != ' ' and y != '', x)))\n",
    "# Remove gender specification (obsolete with next step, but better for visibility)\n",
    "job_titles = job_titles.map(lambda x: list(filter(lambda y: y != 'mw', x)))\n",
    "# Remove short words\n",
    "job_titles = job_titles.map(lambda x: list(filter(lambda y: len(y) > 3, x)))\n",
    "# Join everything into one series\n",
    "job_titles = pd.Series([x for y in job_titles for x in y])\n",
    "len(job_titles.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Training Dataset\n",
    "\n",
    "- Now we can build the training dataset.\n",
    "- For this we need to think about the problem a bit more.\n",
    "- What we are actually doing is a multilabel classification, since many words do have common subwords. For example if the user types \"hel\" the possible labels are \"help\", \"hell\", \"hello\" etc.\n",
    "- However the more characters the user types the less possible labels there are.\n",
    "- Now to build this dataset we start map each subword (starting at the beginning) to the possible target words. \n",
    "- So for a word abcdef we produce the following examples to train the model:\n",
    "    - abc, abcdef\n",
    "    - abcd, abcdef\n",
    "    - abcde, abcdef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_and_label_generator(job_titles):\n",
    "    unique_words = job_titles.unique()\n",
    "\n",
    "    for word in unique_words:\n",
    "        for i in range(3, len(word)):\n",
    "            yield word[:i], word\n",
    "\n",
    "gen = feature_and_label_generator(job_titles)\n",
    "\n",
    "dataset_file = open('dataset.csv', 'w', encoding='utf-8')\n",
    "dataset_file.write('Input,Label\\n')\n",
    "\n",
    "for feature, label in gen:\n",
    "    dataset_file.write(f\"{feature},{label}\\n\")\n",
    "\n",
    "dataset_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: 39926\n",
      "Unique Labels: 5051\n",
      "Unique Inputs: 23396\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "print('Inputs:', len(df))\n",
    "print('Unique Labels:', len(df['Label'].unique()))\n",
    "print('Unique Inputs:', len(df['Input'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Of course we cannot directly input this into a model.\n",
    "- For the labels we have to map all the possible labels to unique ids\n",
    "- For the features we need to think a bit more about how we can represent the relevant properties of the user input:\n",
    "    - The length of the input is probably relevant\n",
    "    - Which characters are used should be represented, maybe similar to a bag-of-words model we could use a bag-of-characters\n",
    "    - The ordering of the characters should also be represented. This could be done by a vector of the same length as the boc, then for each character set the average position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Label</th>\n",
       "      <th>LabelEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc</td>\n",
       "      <td>account</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acco</td>\n",
       "      <td>account</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accou</td>\n",
       "      <td>account</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accoun</td>\n",
       "      <td>account</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man</td>\n",
       "      <td>manager</td>\n",
       "      <td>2697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Input    Label  LabelEncoded\n",
       "0     acc  account            34\n",
       "1    acco  account            34\n",
       "2   accou  account            34\n",
       "3  accoun  account            34\n",
       "4     man  manager          2697"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode Labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df['Label'])\n",
    "df['LabelEncoded'] = label_encoder.transform(df['Label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As mentioned above this is a multilabel classification, therefore we must first group the labels by the inputs, so that we know all possible labels for each input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Label</th>\n",
       "      <th>LabelEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aar</td>\n",
       "      <td>[aarau, aargau]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aara</td>\n",
       "      <td>[aarau]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aarg</td>\n",
       "      <td>[aargau]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aarga</td>\n",
       "      <td>[aargau]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aba</td>\n",
       "      <td>[abap, abacus]</td>\n",
       "      <td>[3, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input            Label LabelEncoded\n",
       "0    aar  [aarau, aargau]       [0, 1]\n",
       "1   aara          [aarau]          [0]\n",
       "2   aarg         [aargau]          [1]\n",
       "3  aarga         [aargau]          [1]\n",
       "4    aba   [abap, abacus]       [3, 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('Input').agg({'Label':lambda x: list(x), 'LabelEncoded': lambda x: list(x)}).reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_boc(chars, char_mapping):\n",
    "    boc = [0]*len(char_mapping)\n",
    "    for char in chars:\n",
    "        boc[char_mapping[char]] += 1\n",
    "    return boc\n",
    "\n",
    "def generate_ordering(chars, char_mapping):\n",
    "    ordering = [[] for _ in range(len(char_mapping))]\n",
    "    for idx, char in enumerate(chars):\n",
    "        ordering[char_mapping[char]].append(idx + 1)\n",
    "    ordering = list(map(lambda x: np.mean(x) if x else 0, ordering))\n",
    "    return ordering\n",
    "    \n",
    "# Generate char_mapping\n",
    "df['chars'] = df['Input'].map(lambda x: list(x))\n",
    "unique_chars = list(set([x for y in df['chars'] for x in y]))\n",
    "char_mapping = dict([(y, x) for (x, y) in enumerate(unique_chars)])\n",
    "\n",
    "# Generate Bag of Characters\n",
    "df['boc'] = df['chars'].map(lambda x: generate_boc(x, char_mapping))\n",
    "# Get length of input\n",
    "df['length'] = df['chars'].map(lambda x: len(x))\n",
    "# Generate ordering\n",
    "df['ordering'] = df['chars'].map(lambda x: generate_ordering(x, char_mapping))\n",
    "# Generate One-Hot encoding for labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(df['LabelEncoded'])\n",
    "df['LabelOneHot'] = df['LabelEncoded'].map(lambda x: np.squeeze(mlb.transform([x])))\n",
    "df.head()\n",
    "df.to_csv('transformed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muy/.local/share/virtualenvs/jobcloud-challenge-hP8ijO2P/lib/python3.6/site-packages/pandas/core/frame.py:3391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "# Merge everything to one row\n",
    "X = df[['boc', 'length', 'ordering']]\n",
    "colnames_boc = list(map(lambda x: 'boc_' + x, char_mapping.keys()))\n",
    "colnames_ord = list(map(lambda x: 'ord_' + x, char_mapping.keys()))\n",
    "\n",
    "X[colnames_boc] = pd.DataFrame(X['boc'].values.tolist(), columns=colnames_boc)\n",
    "X[colnames_ord] = pd.DataFrame(X['ordering'].values.tolist(), columns=colnames_ord)\n",
    "X = X.drop(['boc', 'ordering'], axis=1)\n",
    "\n",
    "y = df['LabelOneHot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>boc_x</th>\n",
       "      <th>boc_n</th>\n",
       "      <th>boc_ü</th>\n",
       "      <th>boc_ö</th>\n",
       "      <th>boc_f</th>\n",
       "      <th>boc_i</th>\n",
       "      <th>boc_ä</th>\n",
       "      <th>boc_g</th>\n",
       "      <th>boc_p</th>\n",
       "      <th>...</th>\n",
       "      <th>ord_j</th>\n",
       "      <th>ord_e</th>\n",
       "      <th>ord_r</th>\n",
       "      <th>ord_y</th>\n",
       "      <th>ord_v</th>\n",
       "      <th>ord_s</th>\n",
       "      <th>ord_t</th>\n",
       "      <th>ord_b</th>\n",
       "      <th>ord_è</th>\n",
       "      <th>ord_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  boc_x  boc_n  boc_ü  boc_ö  boc_f  boc_i  boc_ä  boc_g  boc_p  ...  \\\n",
       "0       3      0      0      0      0      0      0      0      0      0  ...   \n",
       "1       4      0      0      0      0      0      0      0      0      0  ...   \n",
       "2       4      0      0      0      0      0      0      0      1      0  ...   \n",
       "3       5      0      0      0      0      0      0      0      1      0  ...   \n",
       "4       3      0      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "   ord_j  ord_e  ord_r  ord_y  ord_v  ord_s  ord_t  ord_b  ord_è     ord_a  \n",
       "0    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0  1.500000  \n",
       "1    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0  2.333333  \n",
       "2    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0  1.500000  \n",
       "3    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0  2.666667  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0  2.000000  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4    [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: LabelOneHot, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "- As mentioned above it is always important to establish a baseline before running experiments with really complex models.\n",
    "- Therefore we will try to build a simple model based on random forests:\n",
    "    - They are memory intensive but really simple models\n",
    "    - Evaluation on a random forest is rather fast.\n",
    "    - As a baseline they usually provide a good intuition on what is possible.\n",
    "- We will use 5% of the data as the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-f509cbcd93e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_df_to_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/jobcloud-challenge-hP8ijO2P/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/jobcloud-challenge-hP8ijO2P/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0my_store_unique_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mclasses_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_store_unique_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def convert_df_to_np(df):\n",
    "    return np.array(list(map(lambda x: x.astype(int), np.array(df))))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, shuffle=True)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(X_train, convert_df_to_np(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "classification_report(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobcloud_challenge",
   "language": "python",
   "name": "jobcloud_challenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
